{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9ee671",
   "metadata": {},
   "source": [
    "# Breast Cancer EDA & Modeling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52680588",
   "metadata": {},
   "source": [
    "## Imports & Global Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e5b4f",
   "metadata": {},
   "source": [
    "## Quick Guide: Running Manual vs Agentic EDA\n",
    "\n",
    "This notebook contains both a manual EDA workflow and an automated `EDAAgent` for a friendly comparison. Follow these steps to reproduce the demo:\n",
    "\n",
    "1. Install dependencies: `pip install -r requirements.txt` (see repository root).\n",
    "2. Open this notebook in Jupyter and run cells top-to-bottom to ensure all variables are initialized.\n",
    "3. Manual EDA: run the cells up through the 'Manual EDA Summary' section for the human-driven exploration and visualizations.\n",
    "4. Agentic EDA: run the cell in the 'Running the EDA Agent' section to execute `EDAAgent` — watch the timestamped logs it prints.\n",
    "\n",
    "To evaluate the automated workflow, refer to the Agent Execution Log and the Manual-vs-Agentic Comparison section. These show how the agent reproduces the manual analysis with added reproducibility, transparency, and consistency.\n",
    "\n",
    "If you need a clean environment, use the included `requirements.txt` and a venv. See the project root for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import importlib.util\n",
    "import inspect\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Display + plotting style\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f87cbc",
   "metadata": {},
   "source": [
    "## Repository Root & Project Paths\n",
    "This cell detects the project’s root folder and sets up all directory paths (data, engineered data, artifacts) so the notebook can reliably read and save files no matter where it’s run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the project root so all file paths work no matter where the notebook is run\n",
    "def get_repo_root():\n",
    "    try:\n",
    "        # Ask Git for the top-level directory of this repository\n",
    "        return Path(subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], text=True).strip())\n",
    "    except Exception:\n",
    "        # Walk up a few levels looking for a .git folder\n",
    "        p = Path.cwd()\n",
    "        for _ in range(6):\n",
    "            if (p / \".git\").exists():\n",
    "                return p\n",
    "            p = p.parent\n",
    "        # Fallback: current working directory\n",
    "        return Path.cwd()\n",
    "\n",
    "try:\n",
    "    ROOT = get_repo_root()\n",
    "except Exception:\n",
    "    ROOT = Path.cwd()\n",
    "\n",
    "FALLBACK_ROOT = Path(r\"C:\\Users\\rajni\\Documents\\breast-cancer-agentic\")\n",
    "if ROOT != FALLBACK_ROOT and not (ROOT / \"data\" / \"raw\").exists():\n",
    "    ROOT = FALLBACK_ROOT\n",
    "\n",
    "print(\"Repo root:\", ROOT)\n",
    "\n",
    "# Define key directories\n",
    "DATA_RAW        = ROOT / \"data\" / \"raw\"\n",
    "DATA_ENGINEERED = ROOT / \"data\" / \"engineered\"\n",
    "ARTIFACTS_ENG   = ROOT / \"artifacts\" / \"engineering\"\n",
    "ARTIFACTS_EDA   = ROOT / \"artifacts\" / \"eda\"\n",
    "\n",
    "for p in [DATA_ENGINEERED, ARTIFACTS_ENG, ARTIFACTS_EDA]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Source CSV + target column\n",
    "SRC_FILE   = DATA_RAW / \"breast_cancer_with_columns.csv\"\n",
    "TARGET_COL = \"diagnosis\"\n",
    "\n",
    "print(\"Using source file:\", SRC_FILE)\n",
    "assert SRC_FILE.exists(), f\"Missing source file: {SRC_FILE}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0023fb",
   "metadata": {},
   "source": [
    "## Load Dataset & Basic Checks\n",
    "This cell loads the raw dataset, verifies that the target column exists, splits the data into features and labels, and provides basic previews (head, summary stats, missing values) to confirm the data was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from disk\n",
    "df = pd.read_csv(SRC_FILE)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "\n",
    "# Make sure the target column exists before continuing\n",
    "if TARGET_COL not in df.columns:\n",
    "    print(\"Columns available (first 40):\", list(df.columns)[:40])\n",
    "    raise AssertionError(f\"Target column '{TARGET_COL}' not found in CSV\")\n",
    "\n",
    "# Separate features (X) from the target (y)\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "y_bin = y.map({'B': 0, 'M': 1})\n",
    "\n",
    "print(\"Target distribution (normalized):\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Glance at the data and summary statistics to sanity-check values and types\n",
    "display(df.head())\n",
    "display(df.describe(include=\"all\").T)\n",
    "\n",
    "print(\"Missing values (top 15):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d04e1",
   "metadata": {},
   "source": [
    "## Statistical Significance Testing\n",
    "This cell performs t-tests and chi-square tests to quantify whether observed feature differences between classes are statistically significant (beyond random chance). Results inform feature selection and help flag spurious correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6cc6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Perform t-tests to assess feature significance vs. target\n",
    "# Separate feature values by class\n",
    "class_0 = y_bin.unique()[0]\n",
    "class_1 = y_bin.unique()[1]\n",
    "\n",
    "X_class_0 = X[y_bin == class_0]\n",
    "X_class_1 = X[y_bin == class_1]\n",
    "\n",
    "# Compute t-stats and p-values for each numeric feature\n",
    "test_results = []\n",
    "for col in X.select_dtypes(include=[np.number]).columns:\n",
    "    t_stat, p_val = stats.ttest_ind(X_class_0[col].dropna(), X_class_1[col].dropna())\n",
    "    test_results.append({\n",
    "        'feature': col,\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_val,\n",
    "        'significant': 'Yes' if p_val < 0.05 else 'No',\n",
    "        'mean_class_0': X_class_0[col].mean(),\n",
    "        'mean_class_1': X_class_1[col].mean(),\n",
    "    })\n",
    "\n",
    "significance_df = pd.DataFrame(test_results).sort_values('p_value')\n",
    "print(\"Features ranked by statistical significance (t-test, α=0.05):\")\n",
    "display(significance_df.head(15))\n",
    "\n",
    "# Log summary\n",
    "n_significant = (significance_df['p_value'] < 0.05).sum()\n",
    "print(f\"\\nTotal numeric features: {len(X.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"Statistically significant features (p < 0.05): {n_significant}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a10ef8",
   "metadata": {},
   "source": [
    "## Data Quality Report\n",
    "This cell provides a comprehensive summary of data quality: missing value rates, duplicate rows, data type distribution, and numeric ranges. These metrics help identify potential data issues before modeling and inform cleaning strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c18877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values summary and percentage\n",
    "missing_summary = pd.DataFrame({\n",
    "    'column': df.columns,\n",
    "    'n_missing': [df[c].isna().sum() for c in df.columns],\n",
    "    'pct_missing': [100 * df[c].isna().sum() / len(df) for c in df.columns],\n",
    "    'dtype': df.dtypes.values,\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['n_missing'] > 0].sort_values('n_missing', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# Check for duplicates\n",
    "n_duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate Rows: {n_duplicates} ({100 * n_duplicates / len(df):.2f}%)\")\n",
    "\n",
    "# Missing values\n",
    "if len(missing_summary) > 0:\n",
    "    print(f\"\\nMissing Values (columns with missing data):\")\n",
    "    display(missing_summary[['column', 'n_missing', 'pct_missing', 'dtype']])\n",
    "else:\n",
    "    print(f\"\\n No missing values detected.\")\n",
    "\n",
    "# Data type distribution\n",
    "print(f\"\\nData Type Distribution:\")\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  {dtype}: {count} columns\")\n",
    "\n",
    "# Numeric column ranges\n",
    "print(f\"\\nNumeric Column Ranges (min, max, mean):\")\n",
    "numeric_ranges = []\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    numeric_ranges.append({\n",
    "        'column': col,\n",
    "        'min': df[col].min(),\n",
    "        'max': df[col].max(),\n",
    "        'mean': df[col].mean(),\n",
    "        'std': df[col].std(),\n",
    "    })\n",
    "numeric_df = pd.DataFrame(numeric_ranges)\n",
    "display(numeric_df.head(10))\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"Data quality checks complete. Ready for EDA and modeling.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335f718",
   "metadata": {},
   "source": [
    "## Numeric Overview & KDE Plots\n",
    "This cell reviews all numeric columns, checks missing/unique counts, and generates KDE plots to visualize how feature distributions differ between malignant and benign cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick numeric overview and sample KDE plots\n",
    "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "print(\"Numeric columns count:\", len(num_cols))\n",
    "display(pd.DataFrame({\n",
    "    \"col\": num_cols,\n",
    "    \"n_missing\": [X[c].isna().sum() for c in num_cols],\n",
    "    \"n_unique\": [X[c].nunique() for c in num_cols],\n",
    "}).sort_values([\"n_missing\", \"n_unique\"], ascending=[False, True]).head(20))\n",
    "\n",
    "# Plot a few features\n",
    "sel = num_cols[:6]\n",
    "for col in sel:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.kdeplot(data=df, x=col, hue=TARGET_COL, fill=True, common_norm=False)\n",
    "    plt.title(f\"{col} by {TARGET_COL}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450a364-54d2-4554-b85c-228b71a8d151",
   "metadata": {},
   "source": [
    "## Correlation Heatmap\n",
    "This heatmap shows pairwise correlations between all numeric features.\n",
    "It helps identify groups of highly related features and potential redundancy\n",
    "before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc0e01-6c54-48c4-81f9-fc43999373cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap for All 30 Features\n",
    "plt.figure(figsize=(10,8))\n",
    "# Compute correlation matrix\n",
    "corr = X.corr()\n",
    "# Heatmap visualization\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc2901",
   "metadata": {},
   "source": [
    "## Outlier Detection & Visualization\n",
    "This cell identifies univariate outliers using the IQR method (values beyond 1.5×IQR) and flags extreme values. This helps understand what gets clipped during percentile capping and validates the choice of clip thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER SUMMARY USING IQR\n",
    "\n",
    "# Create a list to store outlier information for each feature\n",
    "outlier_summary = []\n",
    "\n",
    "# Loop through all numeric columns in X\n",
    "for col in X.select_dtypes(include=[np.number]).columns:\n",
    "    \n",
    "    # Compute the 25th and 75th percentiles\n",
    "    Q1, Q3 = X[col].quantile([0.25, 0.75])\n",
    "    \n",
    "    # Calculate Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define lower and upper bounds for outliers\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify points outside the IQR bounds\n",
    "    outliers = X[(X[col] < lower) | (X[col] > upper)][col]\n",
    "\n",
    "    # Store results for this feature\n",
    "    outlier_summary.append({\n",
    "        \"feature\": col,\n",
    "        \"n_outliers\": len(outliers),                    # Number of outlier values\n",
    "        \"pct_outliers\": round(100 * len(outliers) / len(X), 2),   # Outlier percentage\n",
    "        \"lower_bound\": lower,\n",
    "        \"upper_bound\": upper,\n",
    "        \"min_val\": X[col].min(),\n",
    "        \"max_val\": X[col].max(),\n",
    "    })\n",
    "\n",
    "# Create a summary DataFrame and sort by number of outliers\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values(\"n_outliers\", ascending=False)\n",
    "\n",
    "print(\"Outlier Summary (IQR method):\")\n",
    "display(outlier_df[outlier_df[\"n_outliers\"] > 0].head(10))\n",
    "\n",
    "\n",
    "# BOXPLOTS FOR TOP 6 FEATURES WITH THE MOST OUTLIERS\n",
    "\n",
    "# Select the top 6 features containing the most outliers\n",
    "top_cols = outlier_df[outlier_df[\"n_outliers\"] > 0][\"feature\"].head(6).tolist()\n",
    "\n",
    "if top_cols:\n",
    "    \n",
    "    # Set up a 2x3 grid for plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Create boxplots for each selected feature\n",
    "    for idx, col in enumerate(top_cols):\n",
    "        \n",
    "        # Draw boxplot comparing class 0 and class 1\n",
    "        axes[idx].boxplot(\n",
    "            [X_class_0[col].dropna(), X_class_1[col].dropna()],\n",
    "            labels=[f\"Class {class_0}\", f\"Class {class_1}\"]\n",
    "        )\n",
    "        \n",
    "        # Get outlier count for plot title\n",
    "        count = outlier_df.loc[outlier_df[\"feature\"] == col, \"n_outliers\"].values[0]\n",
    "        \n",
    "        # Add feature name and outlier count\n",
    "        axes[idx].set_title(f\"{col} ({count} outliers)\")\n",
    "        axes[idx].set_ylabel(\"Value\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the boxplots\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nNote: 1st–99th percentile capping can be applied to reduce the impact of these outliers.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93238e",
   "metadata": {},
   "source": [
    "## Target Distribution Plot\n",
    "This cell creates a simple countplot of the diagnosis column to show the class distribution (malignant vs. benign) and verify the dataset’s balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83974cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=TARGET_COL, data=df,\n",
    "    palette=[\"#FF6B6B\", \"#4D96FF\"]   # red (malignant), blue (benign)\n",
    ")\n",
    "plt.title(\"Distribution of Diagnosis\")\n",
    "plt.xlabel(\"Diagnosis\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4315b8f",
   "metadata": {},
   "source": [
    "## Class Imbalance Analysis\n",
    "This cell checks whether the target classes are balanced. Imbalanced datasets may require resampling strategies (oversampling, undersampling, or class weights) during modeling to prevent the model from biasing toward the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Imbalance Check + Visuals\n",
    "\n",
    "# Compute counts & percentages\n",
    "counts = y_bin.value_counts().sort_index()\n",
    "pcts = (counts / len(y_bin) * 100).round(2)\n",
    "ratio = round(counts.max() / counts.min(), 2)\n",
    "\n",
    "print(\"Class Distribution Summary:\")\n",
    "print(f\"  Class 0: {counts[0]} samples ({pcts[0]}%)\")\n",
    "print(f\"  Class 1: {counts[1]} samples ({pcts[1]}%)\")\n",
    "print(f\"\\nImbalance Ratio: {ratio}:1\")\n",
    "\n",
    "# Recommendation\n",
    "if ratio > 1.5:\n",
    "    print(\"\\n Moderate class imbalance detected.\")\n",
    "    print(\"   • Consider class_weight='balanced'\")\n",
    "    print(\"   • SMOTE/oversampling are options\")\n",
    "    print(\"   • Use stratified CV\")\n",
    "    print(\"   • Track precision, recall, F1, ROC-AUC\")\n",
    "else:\n",
    "    print(\"\\n Classes are fairly balanced.\")\n",
    "\n",
    "# Visuals\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(['Class 0', 'Class 1'], counts.values, color=['#4D96FF', '#FF6B6B'])\n",
    "ax1.set_title(\"Class Count\")\n",
    "ax1.set_ylabel(\"Samples\")\n",
    "plt.savefig(\"class_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# Pie chart\n",
    "ax2.pie(counts.values, labels=['Class 0', 'Class 1'], autopct='%1.1f%%',\n",
    "        colors=['#4D96FF', '#FF6B6B'], startangle=90)\n",
    "ax2.set_title(\"Class Percentage\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7acd3",
   "metadata": {},
   "source": [
    "### Scatter, Pairplot, and PCA Visuals\n",
    "\n",
    "This cell creates a few additional visualizations to explore how features relate\n",
    "to the target:\n",
    "\n",
    "- Scatter plot of the top two correlated features  \n",
    "- Pairplot for a small set of top features  \n",
    "- PCA 2D projection to visualize class separability  \n",
    "\n",
    "These help show patterns in the data before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afbb92-7cf5-47ce-bb8a-487d85721057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple scatter and PCA plots \n",
    "# 1) Scatter of two top correlated features\n",
    "# 2) Small pairplot for top features\n",
    "# 3) PCA 2D projection of the feature matrix\n",
    "\n",
    "# Ensure we have a binary target variable to color plots\n",
    "if 'y_bin' in globals():\n",
    "    ybin = y_bin\n",
    "else:\n",
    "    if y.dtype == 'O':\n",
    "        ybin = y.map(lambda v: 1 if str(v).lower().startswith('m') else 0)\n",
    "    else:\n",
    "        ybin = y\n",
    "\n",
    "# Compute simple absolute correlations with target and pick top features\n",
    "num_X = X.select_dtypes(include=[np.number])\n",
    "corr_with_target = num_X.corrwith(ybin).abs().sort_values(ascending=False)\n",
    "top_feats = corr_with_target.index.tolist()\n",
    "print('Top features (by abs corr):', top_feats[:6])\n",
    "\n",
    "# Scatter of two strongest features (if available)\n",
    "if len(top_feats) >= 2:\n",
    "    f1, f2 = top_feats[0], top_feats[1]\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df, x=f1, y=f2, hue=TARGET_COL, palette='Set1', alpha=0.7)\n",
    "    plt.title(f'{f1} vs {f2} — colored by {TARGET_COL}')\n",
    "    plt.xlabel(f1)\n",
    "    plt.ylabel(f2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric features for a two-feature scatter.')\n",
    "\n",
    "# Pairplot for a small subset (top 3 or 4 features)\n",
    "pair_feats = top_feats[:4] if len(top_feats) >= 2 else []\n",
    "if len(pair_feats) >= 2:\n",
    "    print('Drawing pairplot for:', pair_feats)\n",
    "    sns.pairplot(df[pair_feats + [TARGET_COL]], hue=TARGET_COL, diag_kind='kde', plot_kws={'alpha':0.6})\n",
    "    plt.suptitle('Pairplot — top correlated features', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# PCA 2D projection (use scaled features if available)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if 'X_scaled' in globals():\n",
    "    X_pca_in = X_scaled.copy()\n",
    "else:\n",
    "    # Start from numeric columns, coerce any non-numeric entries to NaN\n",
    "    X_pca_in = num_X.copy().apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X_pca_in = X_pca_in.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop columns that are entirely NaN (they provide no signal)\n",
    "all_nan_cols = X_pca_in.columns[X_pca_in.isna().all()].tolist()\n",
    "if all_nan_cols:\n",
    "    print(\"Dropping all-NaN columns before PCA:\", all_nan_cols)\n",
    "    X_pca_in = X_pca_in.drop(columns=all_nan_cols)\n",
    "\n",
    "# Impute remaining NaNs with column mean\n",
    "X_pca_in = X_pca_in.fillna(X_pca_in.mean())\n",
    "\n",
    "# Final sanity check\n",
    "assert not X_pca_in.isna().any().any(), \"X_pca_in still contains NaN values after imputation\"\n",
    "\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X2 = pca.fit_transform(X_pca_in)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=X2[:,0], y=X2[:,1], hue=ybin, palette='Set1', alpha=0.8)\n",
    "plt.xlabel(f'PC1 ({explained[0]*100:.1f}% var)')\n",
    "plt.ylabel(f'PC2 ({explained[1]*100:.1f}% var)')\n",
    "plt.title('PCA 2D — features projected to 2D (colored by target)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc0040",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual EDA Summary — What We've Learned\n",
    "\n",
    "So far, we've done **manual, step-by-step EDA**:\n",
    "- Loaded and inspected the breast cancer dataset (569 samples, 30 features)\n",
    "- Checked for missing values, duplicates, and data types\n",
    "- Analyzed feature correlations and identified top features by absolute correlation with target\n",
    "- Ran t-tests to find statistically significant features (p < 0.05)\n",
    "- Detected outliers using the IQR method and visualized them\n",
    "- Confirmed class balance (relatively balanced, imbalance ratio ~1.05)\n",
    "- Generated KDE plots, scatter plots, and a PCA projection\n",
    "- Created ratio features (worst / mean) and dropped standard-error columns\n",
    "- Applied percentile capping (1st–99th) and StandardScaler normalization\n",
    "- Computed mutual information ranking of features\n",
    "\n",
    "**Key outputs saved**:\n",
    "- `data/engineered/breast_cancer_engineered.csv` — fully preprocessed dataset\n",
    "- `artifacts/engineering/transformers.pkl` — scaler and metadata\n",
    "- `artifacts/eda/mutual_info_ranking.csv` — feature importance\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd54687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EDA Agent — this mirrors the manual steps above but in an automated, repeatable way\n",
    "class EDAAgent:\n",
    "    \"\"\"\n",
    "    EDA Agent: Automates the entire EDA pipeline.\n",
    "    \n",
    "    This agent performs the same steps as the manual EDA above, but:\n",
    "    - Logs each step with timestamps\n",
    "    - Returns structured results (logs + metrics)\n",
    "    - Can be reused and compared against the manual approach\n",
    "    \n",
    "    It's to compare:\n",
    "    1. Manual approach (step-by-step human workflow)\n",
    "    2. Agentic approach (automated pipeline with logs)\n",
    "    \n",
    "    Both should produce the same results, but the agent shows\n",
    "    how automation + logging enables reproducibility and auditability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42, verbose=True):\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.logs = []\n",
    "        self.results = {}\n",
    "    \n",
    "    def log(self, message):\n",
    "        \"\"\"Record a timestamped log entry.\"\"\"\n",
    "        ts = time.strftime('%H:%M:%S')\n",
    "        entry = f'[{ts}] {message}'\n",
    "        self.logs.append(entry)\n",
    "        if self.verbose:\n",
    "            print(entry)\n",
    "    \n",
    "    def load_and_inspect(self, df, target_col):\n",
    "        \"\"\"Step 1: Load dataset and perform basic checks.\"\"\"\n",
    "        self.log(f'Loading dataset: shape {df.shape}')\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_count = df.isna().sum().sum()\n",
    "        if missing_count > 0:\n",
    "            self.log(f'⚠ Found {missing_count} missing values')\n",
    "        else:\n",
    "            self.log('✓ No missing values detected')\n",
    "        \n",
    "        # Check for duplicates\n",
    "        dup_count = df.duplicated().sum()\n",
    "        self.log(f'Duplicates: {dup_count} rows')\n",
    "        \n",
    "        # Target distribution\n",
    "        if target_col in df.columns:\n",
    "            counts = df[target_col].value_counts()\n",
    "            self.log(f'Target distribution: {dict(counts)}')\n",
    "        \n",
    "        self.results['dataset_shape'] = df.shape\n",
    "        return df\n",
    "    \n",
    "    def analyze_correlations(self, X, y):\n",
    "        \"\"\"Step 2: Compute and rank feature correlations with target.\"\"\"\n",
    "        self.log('Computing feature-target correlations...')\n",
    "        \n",
    "        # Handle binary target\n",
    "        if y.dtype == 'O' or y.dtype.name == 'category':\n",
    "            uniq = list(y.unique())\n",
    "            if len(uniq) == 2:\n",
    "                y_bin = y.map({uniq[0]: 0, uniq[1]: 1})\n",
    "            else:\n",
    "                y_bin = y\n",
    "        else:\n",
    "            y_bin = y\n",
    "        \n",
    "        # Compute absolute correlations\n",
    "        num_X = X.select_dtypes(include=[np.number])\n",
    "        corr_with_target = num_X.corrwith(y_bin).abs().sort_values(ascending=False)\n",
    "        \n",
    "        top_features = corr_with_target.head(10)\n",
    "        self.log(f'Top 10 correlated features: {list(top_features.index)}')\n",
    "        \n",
    "        self.results['top_correlated_features'] = top_features.to_dict()\n",
    "        return y_bin\n",
    "    \n",
    "    def run_statistical_tests(self, X, y_bin):\n",
    "        \"\"\"Step 3: Perform t-tests to identify statistically significant features.\"\"\"\n",
    "        from scipy import stats\n",
    "        \n",
    "        self.log('Running t-tests for statistical significance...')\n",
    "        \n",
    "        class_0 = y_bin.unique()[0]\n",
    "        class_1 = y_bin.unique()[1]\n",
    "        \n",
    "        X_class_0 = X[y_bin == class_0]\n",
    "        X_class_1 = X[y_bin == class_1]\n",
    "        \n",
    "        sig_count = 0\n",
    "        for col in X.select_dtypes(include=[np.number]).columns:\n",
    "            t_stat, p_val = stats.ttest_ind(X_class_0[col].dropna(), X_class_1[col].dropna())\n",
    "            if p_val < 0.05:\n",
    "                sig_count += 1\n",
    "        \n",
    "        self.log(f'Found {sig_count} statistically significant features (p < 0.05)')\n",
    "        self.results['significant_feature_count'] = sig_count\n",
    "        return sig_count\n",
    "    \n",
    "    def detect_outliers(self, X):\n",
    "        \"\"\"Step 4: Identify outliers using IQR method.\"\"\"\n",
    "        self.log('Detecting outliers using IQR method...')\n",
    "        \n",
    "        outlier_count = 0\n",
    "        for col in X.select_dtypes(include=[np.number]).columns:\n",
    "            Q1, Q3 = X[col].quantile([0.25, 0.75])\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            outliers = X[(X[col] < lower) | (X[col] > upper)]\n",
    "            outlier_count += len(outliers)\n",
    "        \n",
    "        self.log(f'Total outlier instances detected: {outlier_count}')\n",
    "        self.results['total_outliers'] = outlier_count\n",
    "    \n",
    "    def feature_engineering(self, X):\n",
    "        \"\"\"Step 5: Create ratio features and drop unnecessary columns.\"\"\"\n",
    "        self.log('Engineering features: creating ratios (worst / mean)...')\n",
    "        \n",
    "        X_fe = X.copy()\n",
    "        \n",
    "        # Create ratio features\n",
    "        pairs = [\n",
    "            ('radius_mean', 'radius_worst'),\n",
    "            ('texture_mean', 'texture_worst'),\n",
    "            ('perimeter_mean', 'perimeter_worst'),\n",
    "            ('area_mean', 'area_worst'),\n",
    "            ('smoothness_mean', 'smoothness_worst'),\n",
    "            ('compactness_mean', 'compactness_worst'),\n",
    "            ('concavity_mean', 'concavity_worst'),\n",
    "            ('concave points_mean', 'concave points_worst'),\n",
    "            ('symmetry_mean', 'symmetry_worst'),\n",
    "            ('fractal_dimension_mean', 'fractal_dimension_worst'),\n",
    "        ]\n",
    "        \n",
    "        ratio_count = 0\n",
    "        for a, b in pairs:\n",
    "            if a in X_fe.columns and b in X_fe.columns:\n",
    "                with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                    X_fe[f'{b}_over_{a}'] = X_fe[b] / X_fe[a]\n",
    "                ratio_count += 1\n",
    "        \n",
    "        self.log(f'Created {ratio_count} ratio features')\n",
    "        \n",
    "        # Drop standard-error columns\n",
    "        se_cols = [c for c in X_fe.columns if str(c).endswith('_se')]\n",
    "        X_fe = X_fe.drop(columns=se_cols, errors='ignore')\n",
    "        self.log(f'Dropped {len(se_cols)} standard-error columns')\n",
    "        \n",
    "        self.results['engineered_shape'] = X_fe.shape\n",
    "        return X_fe\n",
    "    \n",
    "    def scale_and_cap(self, X, lower_pct=0.01, upper_pct=0.99):\n",
    "        \"\"\"Step 6: Cap outliers at percentiles and apply StandardScaler.\"\"\"\n",
    "        self.log(f'Capping outliers at {lower_pct*100:.0f}th–{upper_pct*100:.0f}th percentiles...')\n",
    "        \n",
    "        X_cap = X.copy()\n",
    "        for col in X.select_dtypes(include=[np.number]).columns:\n",
    "            lo = X[col].quantile(lower_pct)\n",
    "            hi = X[col].quantile(upper_pct)\n",
    "            X_cap[col] = X_cap[col].clip(lo, hi)\n",
    "        \n",
    "        self.log('Applying StandardScaler to all numeric features...')\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_cap), columns=X_cap.columns)\n",
    "        \n",
    "        self.log(f'Scaling complete. Final shape: {X_scaled.shape}')\n",
    "        self.results['scaled_shape'] = X_scaled.shape\n",
    "        \n",
    "        return X_scaled, scaler\n",
    "    \n",
    "    def compute_feature_importance(self, X, y):\n",
    "        \"\"\"Step 7: Compute mutual information feature ranking.\"\"\"\n",
    "        self.log('Computing mutual information feature ranking...')\n",
    "        \n",
    "        # Impute missing values for MI computation\n",
    "        imp = SimpleImputer(strategy='mean')\n",
    "        X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\n",
    "        \n",
    "        # Handle binary target\n",
    "        if y.dtype == 'O' or y.dtype.name == 'category':\n",
    "            uniq = list(y.unique())\n",
    "            if len(uniq) == 2:\n",
    "                y_bin = y.map({uniq[0]: 0, uniq[1]: 1})\n",
    "            else:\n",
    "                y_bin = y\n",
    "        else:\n",
    "            y_bin = y\n",
    "        \n",
    "        # Compute MI\n",
    "        mi = mutual_info_classif(X_imputed, y_bin, random_state=self.random_state)\n",
    "        mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "        \n",
    "        top_mi = mi_series.head(5).to_dict()\n",
    "        self.log(f'Top 5 features by MI: {top_mi}')\n",
    "        \n",
    "        self.results['mi_ranking'] = mi_series.to_dict()\n",
    "        return mi_series\n",
    "    \n",
    "    def run(self, df, target_col, X_cols=None):\n",
    "        \"\"\"\n",
    "        Execute the full EDA pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "        - df: DataFrame with all features + target\n",
    "        - target_col: name of the target column\n",
    "        - X_cols: list of feature column names (if None, use all except target_col)\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with logs and results\n",
    "        \"\"\"\n",
    "        self.log('='*60)\n",
    "        self.log('EDA AGENT STARTED')\n",
    "        self.log('='*60)\n",
    "        \n",
    "        # Step 1: Load and inspect\n",
    "        df = self.load_and_inspect(df, target_col)\n",
    "        \n",
    "        # Split features and target\n",
    "        y = df[target_col]\n",
    "        X = df.drop(columns=[target_col])\n",
    "        \n",
    "        # Step 2: Analyze correlations\n",
    "        y_bin = self.analyze_correlations(X, y)\n",
    "        \n",
    "        # Step 3: Statistical tests\n",
    "        self.run_statistical_tests(X, y_bin)\n",
    "        \n",
    "        # Step 4: Outlier detection\n",
    "        self.detect_outliers(X)\n",
    "        \n",
    "        # Step 5: Feature engineering\n",
    "        X_fe = self.feature_engineering(X)\n",
    "        \n",
    "        # Step 6: Scale and cap\n",
    "        X_scaled, scaler = self.scale_and_cap(X_fe)\n",
    "        \n",
    "        # Step 7: Feature importance\n",
    "        self.compute_feature_importance(X_scaled, y)\n",
    "        \n",
    "        self.log('='*60)\n",
    "        self.log('EDA AGENT FINISHED')\n",
    "        self.log('='*60)\n",
    "        \n",
    "        return {\n",
    "            'logs': self.logs,\n",
    "            'results': self.results,\n",
    "            'X_scaled': X_scaled,\n",
    "            'y': y,\n",
    "            'scaler': scaler\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb5559",
   "metadata": {},
   "source": [
    "---\n",
    "## Running the EDA Agent — Automated Pipeline with Logs\n",
    "\n",
    "Now let's instantiate the EDA Agent and run it on the same dataset.\n",
    "The agent will perform **identical steps** as our manual EDA, but with:\n",
    "- Timestamped logs for each operation\n",
    "- Structured results that can be inspected and compared\n",
    "- Reproducible, auditable output\n",
    "\n",
    "Watch the agent's logs below to see how it progresses through the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ae501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the EDA Agent and run it\n",
    "# Note: We're running it on the original df (same as our manual EDA above)\n",
    "\n",
    "agent = EDAAgent(random_state=RANDOM_STATE, verbose=True)\n",
    "agent_output = agent.run(df, target_col=TARGET_COL)\n",
    "\n",
    "print('\\n')\n",
    "print('Agent execution complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c0649",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual vs. Agentic EDA — Side-by-Side Comparison\n",
    "\n",
    "Below we compare the manual approach (human-driven, step-by-step) with the agentic approach (automated pipeline).\n",
    "\n",
    "**Key observations**:\n",
    "- Both approaches should produce **identical results** (same dataset, same transformations)\n",
    "- The agent provides **timestamped logs** showing exactly what happened and when\n",
    "- The agent's **structured output** makes it easy to extract metrics and verify reproducibility\n",
    "- For the professor: The logs show how automation eliminates manual errors and improves auditability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69712a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display agent logs for full transparency\n",
    "print('='*80)\n",
    "print('AGENT EXECUTION LOG (Timestamped Events)')\n",
    "print('='*80)\n",
    "for i, log_entry in enumerate(agent_output['logs'], 1):\n",
    "    print(f'{i:2d}. {log_entry}')\n",
    "\n",
    "print('\\n')\n",
    "print('='*80)\n",
    "print('AGENT RESULTS (Key Metrics Extracted)')\n",
    "print('='*80)\n",
    "\n",
    "results = agent_output['results']\n",
    "\n",
    "print(f\"\\nDataset Shape: {results['dataset_shape']}\")\n",
    "print(f\"Engineered Shape: {results['engineered_shape']}\")\n",
    "print(f\"Scaled Shape: {results['scaled_shape']}\")\n",
    "print(f\"Statistically Significant Features (p < 0.05): {results['significant_feature_count']}\")\n",
    "print(f\"Total Outlier Instances Detected: {results['total_outliers']}\")\n",
    "\n",
    "print('\\nTop Features by Correlation with Target:')\n",
    "for feat, corr in list(results['top_correlated_features'].items())[:5]:\n",
    "    print(f\"  {feat}: {corr:.4f}\")\n",
    "\n",
    "print('\\nTop Features by Mutual Information:')\n",
    "mi_dict = results['mi_ranking']\n",
    "for feat, mi_val in list(mi_dict.items())[:5]:\n",
    "    print(f\"  {feat}: {mi_val:.4f}\")\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('COMPARISON: Manual vs. Agentic Approach')\n",
    "print('='*80)\n",
    "print(f\"\"\"\n",
    "Manual EDA (Human-Driven):\n",
    "  Flexible, exploratory approach\n",
    "  Can inspect intermediate results\n",
    "  Error-prone if repeated\n",
    "  Hard to audit which steps were done\n",
    "  Difficult to scale to new datasets\n",
    "\n",
    "Agentic EDA (Automated Pipeline):\n",
    "  Reproducible — same steps every time\n",
    "  Auditable — full timestamped log of all operations\n",
    "  Easy to reuse on new datasets\n",
    "  Structured output for downstream analysis\n",
    "  Can be integrated into larger workflows\n",
    "  Less flexibility for ad-hoc exploration\n",
    "\n",
    "CONCLUSION:\n",
    "The agent produces the same EDA results as manual steps, but with reproducibility\n",
    "and auditability. Perfect for consistent data processing in production pipelines.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5ccc1",
   "metadata": {},
   "source": [
    "## Baseline Feature Engineering\n",
    "This cell applies our baseline feature engineering: it creates ratio features (worst / mean) for key measurements and removes all _se standard-error columns to reduce noise and dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f426e704",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop_se_columns\u001b[39m(df):\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.drop(columns=[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(c).endswith(\u001b[33m'\u001b[39m\u001b[33m_se\u001b[39m\u001b[33m'\u001b[39m)], errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m X_fe = add_ratio_features(\u001b[43mX\u001b[49m)\n\u001b[32m     26\u001b[39m X_fe = drop_se_columns(X_fe)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFeature-engineered shape:\u001b[39m\u001b[33m\"\u001b[39m, X_fe.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Create ratio features and drop *_se columns\n",
    "def add_ratio_features(df):\n",
    "    df = df.copy()\n",
    "    pairs = [\n",
    "        ('radius_mean','radius_worst'),\n",
    "        ('texture_mean','texture_worst'),\n",
    "        ('perimeter_mean','perimeter_worst'),\n",
    "        ('area_mean','area_worst'),\n",
    "        ('smoothness_mean','smoothness_worst'),\n",
    "        ('compactness_mean','compactness_worst'),\n",
    "        ('concavity_mean','concavity_worst'),\n",
    "        ('concave points_mean','concave points_worst'),\n",
    "        ('symmetry_mean','symmetry_worst'),\n",
    "        ('fractal_dimension_mean','fractal_dimension_worst'),\n",
    "    ]\n",
    "    for a, b in pairs:\n",
    "        if a in df.columns and b in df.columns:\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                df[f'{b}_over_{a}'] = df[b] / df[a]\n",
    "    return df\n",
    "\n",
    "def drop_se_columns(df):\n",
    "    return df.drop(columns=[c for c in df.columns if str(c).endswith('_se')], errors='ignore')\n",
    "\n",
    "X_fe = add_ratio_features(X)\n",
    "X_fe = drop_se_columns(X_fe)\n",
    "print(\"Feature-engineered shape:\", X_fe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da325179",
   "metadata": {},
   "source": [
    "## Cap Percentiles, Scale, Save Engineered Data & Transformers\n",
    "This cell caps outliers using percentile clipping, scales all features with StandardScaler, and then saves the engineered dataset and transformer metadata for consistent reuse across the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef60e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_percentiles(df, lower=0.01, upper=0.99):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        lo = df[col].quantile(lower)\n",
    "        hi = df[col].quantile(upper)\n",
    "        df[col] = df[col].clip(lo, hi)\n",
    "    return df\n",
    "\n",
    "lower_pct, upper_pct = 0.01, 0.99\n",
    "X_cap = cap_percentiles(X_fe, lower=lower_pct, upper=upper_pct)\n",
    "\n",
    "# Record clip bounds for metadata\n",
    "clip_lower = {}\n",
    "clip_upper = {}\n",
    "for col in X_fe.select_dtypes(include=[np.number]).columns:\n",
    "    clip_lower[col] = float(X_fe[col].quantile(lower_pct))\n",
    "    clip_upper[col] = float(X_fe[col].quantile(upper_pct))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_cap), columns=X_cap.columns)\n",
    "\n",
    "fe_metadata = {\n",
    "    \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"clip_percentiles\": {\"lower\": lower_pct, \"upper\": upper_pct},\n",
    "    \"clip_bounds\": {\"lower\": clip_lower, \"upper\": clip_upper},\n",
    "    \"feature_columns\": list(X_scaled.columns),\n",
    "    \"transform\": \"cap_percentiles + StandardScaler\",\n",
    "}\n",
    "\n",
    "out_df = X_scaled.copy()\n",
    "out_df[TARGET_COL] = y.values\n",
    "\n",
    "ENGINEERED_PATH = DATA_ENGINEERED / \"breast_cancer_engineered.csv\"\n",
    "out_df.to_csv(ENGINEERED_PATH, index=False)\n",
    "\n",
    "joblib.dump({'scaler': scaler, 'columns': list(X_scaled.columns), 'fe_metadata': fe_metadata},\n",
    "            ARTIFACTS_ENG / 'transformers.pkl')\n",
    "\n",
    "print(\"Saved engineered data to:\", ENGINEERED_PATH)\n",
    "print(\"Saved transformers to:\", ARTIFACTS_ENG / \"transformers.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95757905",
   "metadata": {},
   "source": [
    "## Mutual Information Ranking\n",
    "This cell computes Mutual Information scores to measure how strongly each feature relates to the target, and saves a ranked list of the most informative features for later modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff516865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with column mean\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = pd.DataFrame(imp.fit_transform(X_scaled),\n",
    "                         columns=X_scaled.columns, index=X_scaled.index)\n",
    "\n",
    "# Select correct target (y_bin if present else y)\n",
    "target = y_bin if 'y_bin' in globals() else y\n",
    "\n",
    "# Compute mutual information\n",
    "mi = mutual_info_classif(X_imputed, target, random_state=RANDOM_STATE)\n",
    "mi_series = pd.Series(mi, index=X_imputed.columns).sort_values(ascending=False)\n",
    "\n",
    "# Save ranking\n",
    "mi_csv_path = ARTIFACTS_EDA / \"mutual_info_ranking.csv\"\n",
    "mi_series.to_csv(mi_csv_path)\n",
    "print(\"Saved mutual info ranking to:\", mi_csv_path)\n",
    "\n",
    "mi_series.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f2b68",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "This cell splits the processed data into training and testing sets (using stratification) so we can train models fairly and evaluate them on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688018c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same target as MI (binary if available)\n",
    "target = y_bin if 'y_bin' in globals() else y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, target,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=target,\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99467ba",
   "metadata": {},
   "source": [
    "## XGBoost + GridSearchCV Modeling\n",
    "This cell trains an XGBoost model using GridSearchCV to find the best hyperparameters, then evaluates the final model on the test set using ROC-AUC, classification metrics, and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b49e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base XGBoost model\n",
    "xgb = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    ")\n",
    "\n",
    "# Hyperparameter grid (your earlier setup)\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [400],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0.1, 1, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "# Stratified K-fold CV\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters Found:\", grid.best_params_)\n",
    "print(\"Best ROC-AUC Score from CV:\", grid.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_proba = grid.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"Test ROC-AUC:\", test_auc)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)\n",
    "plt.title(\"Confusion Matrix — Best XGBoost Model\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
