# -*- coding: utf-8 -*-
"""obiedeh_breast_cancer_agentic_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1USZsULHzHRz-Z1RbSBVrVYtlIiUWTPD3
"""
# ============================================================
# Obinna Edeh - USD - AAI - 501 - G5
# ============================================================
# ============================================================
# SECTION 0: Imports & Global Config
# ============================================================
import os
import json
import csv
import datetime
import smtplib
from email.mime.text import MIMEText
from typing import Dict, Any, Optional

import numpy as np
import pandas as pd

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from xgboost import XGBClassifier

from sklearn.feature_selection import RFECV

import shap

# ---- Parallelism config ----
# Use -1 to use all cores (faster but heavier),
# or 1 for more predictable behavior.
N_JOBS = -1

# ---- Terminal Color Helpers (ANSI) ----
COLOR_RESET = "\033[0m"
COLOR_BOLD = "\033[1m"
COLOR_RED = "\033[91m"
COLOR_GREEN = "\033[92m"
COLOR_YELLOW = "\033[93m"
COLOR_CYAN = "\033[96m"
COLOR_MAGENTA = "\033[95m"
COLOR_BLUE = "\033[94m"
COLOR_DIM = "\033[2m"

# ---- Global placeholders ----
X = None
y = None
feature_names = None
target_names = None

X_train = None
X_test = None
y_train = None
y_test = None

cv = None

results = []            # list of dicts for comparison
trained_models = {}     # model_name -> fitted estimator
deployed_model = None   # chosen best model
MALIGNANT_THRESHOLD = 0.5
shap_explainer = None
feature_means = None


# ============================================================
# SECTION 1: Data Loading & Split
# ============================================================
def load_breast_data(test_size: float = 0.2, random_state: int = 42, n_splits: int = 5):
    """
    Load the Wisconsin Breast Cancer dataset and set up train/test split and CV.
    Populates global variables X, y, feature_names, target_names, X_train, etc.
    """
    global X, y, feature_names, target_names
    global X_train, X_test, y_train, y_test, cv, feature_means

    data = load_breast_cancer()
    X = data.data
    y = data.target
    feature_names = data.feature_names
    target_names = data.target_names

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, stratify=y, random_state=random_state
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    # Precompute means for interactive defaults
    feature_means = {fname: float(np.mean(X[:, i])) for i, fname in enumerate(feature_names)}

    print("\n" + "="*80)
    print("üì• DATA LOADING")
    print("="*80)
    print("X shape:", X.shape)
    print("y shape:", y.shape)
    print("Train size:", X_train.shape[0], "Test size:", X_test.shape[0])
    print("="*80)


# ============================================================
# SECTION 2: Model Training Utilities
# ============================================================
def evaluate_model(name: str, model, y_test, y_pred, y_proba=None):
    """Compute metrics, print them, and store them for comparison."""
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan

    print("\n" + "-"*80)
    print(f"üìä {name} ‚Äî TEST PERFORMANCE")
    print("-"*80)
    print(f"Accuracy:   {acc:.4f}")
    print(f"F1-score:   {f1:.4f}")
    print(f"ROC AUC:    {roc:.4f}")
    print("\nClassification report:")
    print(classification_report(y_test, y_pred, target_names=target_names))

    results.append({
        "Model": name,
        "Accuracy": acc,
        "F1-score": f1,
        "ROC AUC": roc
    })

    trained_models[name] = model
    print("-"*80)


def train_logistic_regression():
    print("\n" + "="*80)
    print("üí† LOGISTIC REGRESSION ‚Äî TRAINING & TUNING")
    print("="*80)

    pipe_lr = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))
    ])

    # Medium grid
    param_grid_lr = {
        "clf__C": [0.01, 0.1, 1, 10],
        "clf__penalty": ["l1", "l2"]
    }

    print("\n--- Running GridSearchCV for Logistic Regression ---")

    grid_lr = GridSearchCV(
        estimator=pipe_lr,
        param_grid=param_grid_lr,
        cv=cv,
        scoring="roc_auc",
        n_jobs=N_JOBS
    )

    grid_lr.fit(X_train, y_train)

    print("\nBest Hyperparameters:")
    print(grid_lr.best_params_)
    print("Best CV ROC AUC:", grid_lr.best_score_)

    best_lr = grid_lr.best_estimator_
    y_pred = best_lr.predict(X_test)
    y_proba = best_lr.predict_proba(X_test)[:, 1]

    evaluate_model("Logistic Regression", best_lr, y_test, y_pred, y_proba)

    print("Top 10 Most Important Coefficients (Absolute Value):")
    lr_coeffs = best_lr.named_steps["clf"].coef_[0]
    feature_importance_lr = pd.Series(
        lr_coeffs, index=feature_names
    ).sort_values(key=np.abs, ascending=False)
    print(feature_importance_lr.head(10))
    print("="*80)


def train_random_forest():
    print("\n" + "="*80)
    print("üå≤ RANDOM FOREST ‚Äî TRAINING & TUNING")
    print("="*80)

    rf = RandomForestClassifier(random_state=42)

    param_grid_rf = {
        "n_estimators": [100, 300],
        "max_depth": [None, 5, 10],
        "min_samples_split": [2, 5],
        "min_samples_leaf": [1, 2],
    }

    print("\n--- Running GridSearchCV for Random Forest ---")

    grid_rf = GridSearchCV(
        estimator=rf,
        param_grid=param_grid_rf,
        cv=cv,
        scoring="roc_auc",
        n_jobs=N_JOBS
    )

    grid_rf.fit(X_train, y_train)

    print("\nBest Hyperparameters:")
    print(grid_rf.best_params_)
    print("Best CV ROC AUC:", grid_rf.best_score_)

    best_rf = grid_rf.best_estimator_
    y_pred = best_rf.predict(X_test)
    y_proba = best_rf.predict_proba(X_test)[:, 1]

    evaluate_model("Random Forest", best_rf, y_test, y_pred, y_proba)

    print("Top 10 Feature Importances:")
    rf_importance = pd.Series(
        best_rf.feature_importances_, index=feature_names
    ).sort_values(ascending=False)
    print(rf_importance.head(10))
    print("="*80)


def train_xgboost():
    print("\n" + "="*80)
    print("‚ö° XGBOOST ‚Äî TRAINING & TUNING")
    print("="*80)

    xgb = XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        random_state=42,
        tree_method="hist"
    )

    param_grid_xgb = {
        "n_estimators": [100, 300],
        "max_depth": [3, 5],
        "learning_rate": [0.01, 0.1],
        "subsample": [0.8, 1.0],
        "colsample_bytree": [0.8, 1.0],
    }

    print("\n--- Running GridSearchCV for XGBoost ---")

    grid_xgb = GridSearchCV(
        estimator=xgb,
        param_grid=param_grid_xgb,
        cv=cv,
        scoring="roc_auc",
        n_jobs=N_JOBS
    )

    grid_xgb.fit(X_train, y_train)

    print("\nBest Hyperparameters:")
    print(grid_xgb.best_params_)
    print("Best CV ROC AUC:", grid_xgb.best_score_)

    best_xgb = grid_xgb.best_estimator_
    y_pred = best_xgb.predict(X_test)
    y_proba = best_xgb.predict_proba(X_test)[:, 1]

    evaluate_model("XGBoost", best_xgb, y_test, y_pred, y_proba)

    print("Top 10 Feature Importances:")
    xgb_importance = pd.Series(
        best_xgb.feature_importances_, index=feature_names
    ).sort_values(ascending=False)
    print(xgb_importance.head(10))
    print("="*80)


def train_svm():
    print("\n" + "="*80)
    print("üß† SVM (RBF Kernel) ‚Äî TRAINING & TUNING")
    print("="*80)

    pipe_svm = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", SVC(probability=True))
    ])

    param_grid_svm = {
        "clf__C": [0.1, 1, 10],
        "clf__gamma": ["scale", 0.01, 0.001],
        "clf__kernel": ["rbf"]
    }

    print("\n--- Running GridSearchCV for SVM ---")

    grid_svm = GridSearchCV(
        estimator=pipe_svm,
        param_grid=param_grid_svm,
        cv=cv,
        scoring="roc_auc",
        n_jobs=N_JOBS
    )

    grid_svm.fit(X_train, y_train)

    print("\nBest Hyperparameters:")
    print(grid_svm.best_params_)
    print("Best CV ROC AUC:", grid_svm.best_score_)

    best_svm = grid_svm.best_estimator_
    y_pred = best_svm.predict(X_test)
    y_proba = best_svm.predict_proba(X_test)[:, 1]

    evaluate_model("SVM (RBF)", best_svm, y_test, y_pred, y_proba)
    print("="*80)


def run_all_models():
    """Train LR, RF, XGB, SVM sequentially with CV + grid search."""
    train_logistic_regression()
    train_random_forest()
    train_xgboost()
    train_svm()


# ============================================================
# SECTION 3: Optional RFECV Feature Selection
# ============================================================
def run_rfecv_and_xgb():
    """
    Optional: RFECV with Logistic Regression (Pipeline) for feature selection,
    then train a simple XGBoost on selected features.
    """
    print("\n" + "="*80)
    print("üîç RFECV FEATURE SELECTION + XGBOOST")
    print("="*80)

    base_lr = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=1000, solver="liblinear"))
    ])

    rfecv = RFECV(
        estimator=base_lr,
        step=1,
        cv=cv,
        scoring="roc_auc",
        n_jobs=N_JOBS,
        importance_getter="named_steps.clf.coef_"  # key fix
    )

    print("\n--- Running RFECV with Logistic Regression ---")
    rfecv.fit(X_train, y_train)

    print("\n[RFECV] selected number of features:", rfecv.n_features_)

    support_mask = rfecv.support_
    selected_features = feature_names[support_mask]
    print("[RFECV] Selected features:", list(selected_features))

    X_train_sel = X_train[:, support_mask]
    X_test_sel = X_test[:, support_mask]

    xgb_sel = XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        random_state=42,
        tree_method="hist"
    )

    print("\n--- Training XGBoost on RFECV-selected features ---")
    xgb_sel.fit(X_train_sel, y_train)
    y_pred = xgb_sel.predict(X_test_sel)
    y_proba = xgb_sel.predict_proba(X_test_sel)[:, 1]

    evaluate_model("XGBoost (RFE-selected features)", xgb_sel, y_test, y_pred, y_proba)
    print("="*80)


# ============================================================
# SECTION 4: Model Comparison & Choose Deployed Model
# ============================================================
def summarize_and_choose_model(preferred: str = "XGBoost"):
    """
    Display comparison table and pick a deployed model.
    """
    global deployed_model

    print("\n" + "="*80)
    print("üèÜ MODEL COMPARISON & SELECTION")
    print("="*80)

    if not results:
        print("No models trained yet! Run run_all_models() first.")
        print("="*80)
        return

    df = pd.DataFrame(results).sort_values(by="ROC AUC", ascending=False)

    print("\n--- Model Performance Table ---")
    print(df)
    print("-"*80)

    if preferred in trained_models:
        deployed_model = trained_models[preferred]
        print(f"Selected preferred model: {preferred}")
    else:
        best_name = df.iloc[0]["Model"]
        deployed_model = trained_models[best_name]
        print(f"Preferred model not found ‚Äî falling back to: {best_name}")

    print("Deployed model:", type(deployed_model).__name__)
    print("="*80)


# ============================================================
# SECTION 5: SHAP Explainer for Deployed Model
# ============================================================
def setup_shap_explainer():
    """
    Build a SHAP explainer for the deployed model.
    Intended for tree-based models like XGBoost/RandomForest, but
    we‚Äôll still try for others.
    """
    global shap_explainer

    print("\n" + "="*80)
    print("üßæ SHAP EXPLAINER SETUP")
    print("="*80)

    if deployed_model is None:
        print("Deployed model not set. Call summarize_and_choose_model() first.")
        print("="*80)
        return

    shap.initjs()
    shap_explainer = shap.TreeExplainer(deployed_model)
    print("SHAP explainer initialized for:", type(deployed_model).__name__)
    print("="*80)


# ============================================================
# SECTION 6: Agentic Patient Triage Module (with SHAP + Email)
# ============================================================
def send_email_to_doctor(
    report_text: str,
    doctor_email: str,
    sender_email: str,
    smtp_host: str,
    smtp_port: int,
    smtp_user: str,
    smtp_password: str,
    subject: str = "Breast Imaging Case ‚Äì Automated Triage Alert"
) -> None:
    """
    Simple SMTP email helper.
    WARNING: demo only; do not hardcode secrets in production.
    """
    msg = MIMEText(report_text)
    msg["Subject"] = subject
    msg["From"] = sender_email
    msg["To"] = doctor_email

    with smtplib.SMTP_SSL(smtp_host, smtp_port) as server:
        server.login(smtp_user, smtp_password)
        server.send_message(msg)


def patient_triage_agent(
    patient_features: Dict[str, float],
    model,
    feature_names,
    patient_id: str,
    doctor_email: Optional[str] = None,
    trigger_email: bool = True,
    email_config: Optional[Dict[str, Any]] = None,
    threshold: float = MALIGNANT_THRESHOLD,
    explainer: Optional[Any] = None,
    top_k: int = 5
) -> Dict[str, Any]:
    """
    Agentic triage: run patient features through model, return report + SHAP explanation.
    """

    # 1) Build feature vector in correct order
    feature_vector = []
    missing_features = []

    for fname in feature_names:
        if fname in patient_features:
            feature_vector.append(patient_features[fname])
        else:
            feature_vector.append(0.0)
            missing_features.append(fname)

    X_patient = np.array(feature_vector).reshape(1, -1)

    # 2) Prediction
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X_patient)[0][1]
    else:
        if hasattr(model, "decision_function"):
            raw = model.decision_function(X_patient)[0]
            proba = 1 / (1 + np.exp(-raw))
        else:
            label_raw = model.predict(X_patient)[0]
            proba = float(label_raw)

    label = "malignant" if proba >= threshold else "benign"
    risk_level = "HIGH RISK" if label == "malignant" else "LOW RISK"

    # 3) SHAP explanation
    shap_summary_lines = []
    shap_values_patient = None

    if explainer is not None:
        try:
            shap_values = explainer.shap_values(X_patient)
            if isinstance(shap_values, list):
                shap_values_patient = shap_values[1][0]
            else:
                shap_values_patient = shap_values[0]

            abs_vals = np.abs(shap_values_patient)
            top_idx = np.argsort(-abs_vals)[:top_k]

            for i in top_idx:
                direction = (
                    "‚Üë risk (toward malignant)" if shap_values_patient[i] > 0
                    else "‚Üì risk (toward benign)"
                )
                shap_summary_lines.append(
                    f"- {feature_names[i]}: "
                    f"value={X_patient[0, i]:.3f}, "
                    f"SHAP={shap_values_patient[i]:.4f} ({direction})"
                )
        except Exception as e:
            shap_summary_lines.append(f"(SHAP explanation error: {e})")

    # 4) Report text
    timestamp = datetime.datetime.now().isoformat(timespec="seconds")

    report_text = f"""
Breast Imaging Triage Report (Demo Agent)
-----------------------------------------
Timestamp:      {timestamp}
Patient ID:     {patient_id}

Model Used:     {type(model).__name__}
Predicted Class: {label.upper()}
Risk Level:      {risk_level}
P(malignant):    {proba:.4f}
Threshold used:  {threshold:.2f}

Clinical Interpretation (NON-DIAGNOSTIC):
    - If P(malignant) >= threshold -> "likely malignant": recommend urgent radiologist review.
    - Otherwise -> "likely benign": routine follow-up per clinical protocol.

Missing Features (set to 0.0 in this run):
    {', '.join(missing_features) if missing_features else 'None'}
"""

    if shap_summary_lines:
        report_text += "\nTop feature contributions (SHAP-based, this patient):\n"
        report_text += "\n".join(shap_summary_lines) + "\n"

    report_text += """
IMPORTANT:
    This output is for research/educational use only.
    It is NOT a medical diagnosis and must NOT be used as the sole basis
    for any clinical decision. A qualified physician must review the case.
"""

    # 5) Optional email
    email_sent = False
    email_error = None
    email_attempted = (label == "malignant") and trigger_email and bool(doctor_email and email_config)

    if email_attempted:
        try:
            send_email_to_doctor(
                report_text=report_text,
                doctor_email=doctor_email,
                sender_email=email_config["sender_email"],
                smtp_host=email_config["smtp_host"],
                smtp_port=email_config["smtp_port"],
                smtp_user=email_config["smtp_user"],
                smtp_password=email_config["smtp_password"],
                subject=f"[ALERT] High-Risk Breast Imaging Case ‚Äì Patient {patient_id}"
            )
            email_sent = True
        except Exception as e:
            email_error = str(e)

    return {
        "patient_id": patient_id,
        "timestamp": timestamp,
        "predicted_label": label,
        "risk_level": risk_level,
        "p_malignant": proba,
        "threshold": threshold,
        "report_text": report_text,
        "email_attempted": email_attempted,
        "email_sent": email_sent,
        "email_error": email_error,
        "missing_features": missing_features,
        "shap_values": shap_values_patient,
        "top_features_text": shap_summary_lines,
    }


# ============================================================
# SECTION 7: Logging Helper (Save Cases)
# ============================================================
def save_case_result(result: Dict[str, Any], base_dir: str = "cases") -> Dict[str, str]:
    """
    Save a triage result as:
      - JSON file per case
      - Append/log line in a CSV registry
    """
    os.makedirs(base_dir, exist_ok=True)

    json_path = os.path.join(base_dir, f"{result['patient_id']}.json")
    with open(json_path, "w") as f:
        json.dump(result, f, indent=2, default=str)

    csv_path = os.path.join(base_dir, "cases_log.csv")
    fieldnames = [
        "patient_id",
        "timestamp",
        "predicted_label",
        "risk_level",
        "p_malignant",
        "threshold",
        "email_attempted",
        "email_sent",
        "email_error",
    ]

    file_exists = os.path.exists(csv_path)
    with open(csv_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow({
            "patient_id": result["patient_id"],
            "timestamp": result["timestamp"],
            "predicted_label": result["predicted_label"],
            "risk_level": result["risk_level"],
            "p_malignant": result["p_malignant"],
            "threshold": result["threshold"],
            "email_attempted": result["email_attempted"],
            "email_sent": result["email_sent"],
            "email_error": result["email_error"],
        })

    return {"json_path": json_path, "csv_path": csv_path}

# ============================================================
# SECTION 8A: Simulated Agent Sensor & Actuator ‚Äì Email Summary
# ============================================================
def sensor_actuator_email_alert(result, to_email="oncology_team@example.com"):
    """
    Simulated agent 'sensor + actuator':
    - SENSOR: Listens for each completed triage result.
    - ACTUATOR: If prediction is malignant, crafts an email-style
      alert message with a brief report summary.
    - Appends 'Follow Needed.' to the message for malignant cases.
    - This is a SIMULATION: it only prints to console (no real email).
    """

    # Always "sense" the event, but only "act" on malignant
    pred_label = result.get("predicted_label", "").lower()
    if pred_label != "malignant":
        # You could uncomment this if you want explicit non-alert traces:
        # print(f"{COLOR_DIM}[Sensor] No alert generated (benign prediction).{COLOR_RESET}")
        return

    patient_id   = result.get("patient_id", "UNKNOWN_ID")
    risk_level   = result.get("risk_level", "unknown")
    p_malignant  = result.get("p_malignant", 0.0)
    threshold    = result.get("threshold", 0.5)
    report_text  = result.get("report_text", "").strip()

    # Build a concise SHAP summary line, if available
    top_feats = result.get("top_features_text", []) or []
    top_feats_snippet = "; ".join(top_feats[:3])  # first 3 only

    subject = (
        f"[SIM-AGENT ALERT] Breast Imaging ‚Äì {patient_id} MALIGNANT ‚Äì Follow Up Needed."
    )

    body_lines = [
        f"To: {to_email}",
        "Subject: " + subject,
        "",
        "Dear Clinical Team,",
        "",
        f"A simulated agent sensor detected a malignant triage result for patient {patient_id}.",
        "",
        "Summary:",
        f"  ‚Ä¢ Predicted Class : MALIGNANT",
        f"  ‚Ä¢ Risk Level      : {risk_level}",
        f"  ‚Ä¢ P(malignant)    : {p_malignant:.4f}",
        f"  ‚Ä¢ Decision Threshold: {threshold:.2f}",
    ]

    if top_feats_snippet:
        body_lines.append("")
        body_lines.append("Key feature contributions (SHAP, top 3):")
        body_lines.append("  " + top_feats_snippet)

    if report_text:
        body_lines.append("")
        body_lines.append("Report Summary:")
        body_lines.append("  " + report_text.replace("\n", "\n  "))

    body_lines.append("")
    body_lines.append("Follow Up Needed.")
    body_lines.append("")
    body_lines.append(
        "(Simulation only ‚Äì no real email was sent. This system is for research/education.)"
    )

    email_message = "\n".join(body_lines)

    print("\n" + "-" * 80)
    print(f"{COLOR_BOLD}{COLOR_MAGENTA}üìß SIMULATED AGENT EMAIL ‚Äì SENSOR & ACTUATOR{COLOR_RESET}")
    print("-" * 80)
    print(email_message)
    print("-" * 80 + "\n")


# ============================================================
# SECTION 8: Synthetic Patient Test Lab (ALL FEATURES SHOWN)
# ============================================================
def interactive_agent_session():
    """
    Synthetic test lab:
    - Shows feature range guide.
    - Asks if user wants to generate synthetic patients.
    - If yes, generates 10 synthetic patients sampled from dataset
      (~30% malignant / 70% benign) but does NOT show any true labels.
    - Displays full feature table (all 30 columns).
    - User can enter patient_id to run triage agent.
    """
    if deployed_model is None or shap_explainer is None:
        print("\n" + "="*80)
        print("‚ö†Ô∏è Synthetic Test Lab requires a deployed model and SHAP explainer.")
        print("   Run:")
        print("      load_breast_data()")
        print("      run_all_models()")
        print("      summarize_and_choose_model(...)")
        print("      setup_shap_explainer()")
        print("="*80)
        return

    header = f"{COLOR_CYAN}{COLOR_BOLD}*** Breast Imaging ‚Äì Synthetic Patient Lab ***{COLOR_RESET}"
    print("\n" + header)
    print(f"{COLOR_DIM}Type 'exit' anytime to quit.{COLOR_RESET}\n")

    # ------------------------------------------------------------
    # Feature Range Guide
    # ------------------------------------------------------------
    print(f"{COLOR_BOLD}{COLOR_BLUE}üß≠ Feature Range Guide{COLOR_RESET}")
    print(f"{COLOR_DIM}Observed ranges from real dataset.{COLOR_RESET}\n")

    print(f"{COLOR_BOLD}{'Feature':40s} | {'Min':>10s} | {'Max':>10s} | {'Mean':>10s}{COLOR_RESET}")
    print("-"*80)
    for i, fname in enumerate(feature_names):
        col = X[:, i]
        print(f"{fname:40s} | {col.min():10.3f} | {col.max():10.3f} | {col.mean():10.3f}")
    print("-"*80)
    print(f"{COLOR_GREEN}Synthetic patients will be created within these real observed ranges.{COLOR_RESET}")
    print("="*80)

    # ------------------------------------------------------------
    # Ask user if testing should begin
    # ------------------------------------------------------------
    resp = input("\nGenerate 10 synthetic patients for testing? (yes/no): ").strip().lower()
    if resp in ["no", "n", "exit", ""]:
        print(f"{COLOR_MAGENTA}\nExiting synthetic test lab. Goodbye!{COLOR_RESET}")
        return

    # ------------------------------------------------------------
    # Generate 10 synthetic patients (~30% malignant, 70% benign)
    # ------------------------------------------------------------
    print("\n" + "-"*80)
    print("üß™ Generating 10 synthetic patients...")
    print("-"*80)

    num_patients = 10
    idx_mal = np.where(y == 0)[0]
    idx_ben = np.where(y == 1)[0]

    num_mal = max(1, int(round(0.3 * num_patients)))
    num_ben = num_patients - num_mal

    rng = np.random.default_rng()

    mal_sample = rng.choice(idx_mal, size=num_mal, replace=False)
    ben_sample = rng.choice(idx_ben, size=num_ben, replace=False)

    all_idx = np.concatenate([mal_sample, ben_sample])
    rng.shuffle(all_idx)

    X_syn = X[all_idx, :]

    # Build DataFrame with ALL feature columns visible
    df_syn = pd.DataFrame(X_syn, columns=feature_names)
    df_syn["patient_id"] = ["P%03d" % (i + 1) for i in range(num_patients)]
    df_syn = df_syn[["patient_id"] + list(feature_names)]

    # ------------------------------------------------------------
    # SHOW TRANSPOSED FEATURE TABLE (Top & Bottom 5 Features)
    # ------------------------------------------------------------
    df_display = df_syn.set_index("patient_id").T
    df_display_top = df_display.head(5)
    df_display_bottom = df_display.tail(5)

    print("\n" + "="*80)
    print("üìä SYNTHETIC PATIENT FEATURE TABLE (TRANSPOSED ‚Äî Top & Bottom 5 Features)")
    print("="*80)
    print(df_display_top.to_string())
    print("...\n")
    print(df_display_bottom.to_string())
    print("="*80)
    print(f"{COLOR_DIM}Rows = Features, Columns = Patients (P001‚Ä¶P00N){COLOR_RESET}")
    print(f"{COLOR_DIM}Enter a patient_id to run triage. Use 'table' to reprint.{COLOR_RESET}")

    # ------------------------------------------------------------
    # LOOP ‚Äî ALLOW TESTING EACH PATIENT
    # ------------------------------------------------------------
    while True:
        pid = input("\nEnter patient_id to test ('table' to reprint, 'exit' to quit): ").strip()

        if pid.lower() == "exit":
            print(f"{COLOR_MAGENTA}\nExiting synthetic test lab. Goodbye!{COLOR_RESET}")
            break

        if pid.lower() == "table":
            # ------------------------------------------------------------
            # SHOW TRANSPOSED FEATURE TABLE (Top & Bottom 5 Features)
            # ------------------------------------------------------------
            df_display = df_syn.set_index("patient_id").T
            df_display_top = df_display.head(5)
            df_display_bottom = df_display.tail(5)

            print("\n" + "="*80)
            print("üìä SYNTHETIC PATIENT FEATURE TABLE (TRANSPOSED ‚Äî Top & Bottom 5 Features)")
            print("="*80)
            print(df_display_top.to_string())
            print("...\n")
            print(df_display_bottom.to_string())
            print("="*80)
            print(f"{COLOR_DIM}Rows = Features, Columns = Patients (P001‚Ä¶P00N){COLOR_RESET}")
            #print(f"{COLOR_DIM}Enter a patient_id to run triage. Use 'table' to reprint.{COLOR_RESET}")
            continue

        # Validate patient_id exists
        match = df_syn[df_syn["patient_id"] == pid]
        if match.empty:
            print(f"{COLOR_RED}‚ùó patient_id '{pid}' not found. Try again.{COLOR_RESET}")
            continue

        row = match.iloc[0]
        patient_data = {fname: float(row[fname]) for fname in feature_names}

        print(f"\n{COLOR_YELLOW}Running Agentic Clinical Triage for {pid}...{COLOR_RESET}\n")

        # Run triage
        result = patient_triage_agent(
            patient_features=patient_data,
            model=deployed_model,
            feature_names=feature_names,
            patient_id=pid,
            doctor_email=None,
            trigger_email=False,
            email_config=None,
            threshold=MALIGNANT_THRESHOLD,
            explainer=shap_explainer,
            top_k=5
        )

        risk_color = COLOR_RED if result["predicted_label"] == "malignant" else COLOR_GREEN

        print(f"{COLOR_BOLD}{risk_color}===== TRIAGE RESULT for {pid} ====={COLOR_RESET}")
        print(result["report_text"])
        print(f"{COLOR_BOLD}{risk_color}==================================={COLOR_RESET}")

        print(
            f"{COLOR_BOLD}Model Interpretation:{COLOR_RESET} "
            f"{risk_color}{result['predicted_label'].upper()}{COLOR_RESET} "
            f"(p = {result['p_malignant']:.4f})"
        )

        if result["top_features_text"]:
            print(f"\n{COLOR_BOLD}Top SHAP Contributors:{COLOR_RESET}")
            for line in result["top_features_text"]:
                if "‚Üë risk" in line:
                    print("  " + COLOR_RED + line + COLOR_RESET)
                elif "‚Üì risk" in line:
                    print("  " + COLOR_GREEN + line + COLOR_RESET)
                else:
                    print("  " + line)

        paths = save_case_result(result)
        print(
            f"{COLOR_DIM}\n(case saved: {paths['json_path']} & {paths['csv_path']}){COLOR_RESET}"
        )

        # Simulated Agent Sensor + Actuator (auto-triggered after each test)
        sensor_actuator_email_alert(result)



    demo.launch()

# 1) Load data
load_breast_data()

# 2) Train & tune models
run_all_models()

# 3) RFE + XGB
run_rfecv_and_xgb()

# 4) Choose deployed model (e.g., XGBoost)
summarize_and_choose_model(preferred="XGBoost")

# 5) Set up SHAP
setup_shap_explainer()

# 6) Start interactive CLI (type 'exit' to quit)
interactive_agent_session()
